{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ef1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.layers import Conv2D , Flatten ,Dense , Dropout , MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba05c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the current working dir \n",
    "os.chdir('F:/trigger-word-detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0183ce48",
   "metadata": {},
   "source": [
    "# loading the wav file and decode it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42bf58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900082d7",
   "metadata": {},
   "source": [
    "# create the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "307719cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ds = tf.data.Dataset.list_files(os.path.join(os.getcwd() , 'data' , 'recorded-data' , 'positive' ,'*.wav'))\n",
    "neg_ds = tf.data.Dataset.list_files(os.path.join(os.getcwd() , 'data' , 'recorded-data' , 'negative' ,'*.wav'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b393f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label the data \n",
    "labeled_pos_ds = tf.data.Dataset.zip((pos_ds , tf.data.Dataset.from_tensor_slices(tf.ones(len(pos_ds)))))\n",
    "labeled_neg_ds = tf.data.Dataset.zip((neg_ds , tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg_ds)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f4ee8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = labeled_pos_ds.concatenate(labeled_neg_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7bf763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path, label): \n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    # zero pad the inputs to make them all the same legnth \n",
    "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84665200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(preprocess).cache().shuffle(1000).batch(8).prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "900c84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds.take(16) \n",
    "val_ds = ds.skip(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93e5ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = train_ds.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dab156cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1491, 257, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca3b83",
   "metadata": {},
   "source": [
    "# the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "51683c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16 , (3,3) , padding='same' , activation='relu' ,input_shape =(1491 , 257 , 1 )) , \n",
    "    MaxPooling2D((2,2)) , \n",
    "    Conv2D(16 , (3,3) , padding= 'same' , activation='relu') , \n",
    "    Flatten() , \n",
    "    Dense(128 , activation= 'relu') , \n",
    "    Dropout(.2) , \n",
    "    Dense(1, activation ='sigmoid')\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e27a5f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 1491, 257, 16)     160       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 745, 128, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 745, 128, 16)      2320      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1525760)           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               195297408 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 195,300,017\n",
      "Trainable params: 195,300,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a16ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d86cbfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "16/16 [==============================] - 80s 4s/step - loss: 1.4495 - recall_1: 0.8065 - precision_1: 0.7937 - val_loss: 0.0104 - val_recall_1: 1.0000 - val_precision_1: 1.0000\n",
      "Epoch 2/4\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.0178 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 0.0150 - val_recall_1: 1.0000 - val_precision_1: 1.0000\n",
      "Epoch 3/4\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.0092 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 0.0017 - val_recall_1: 1.0000 - val_precision_1: 1.0000\n",
      "Epoch 4/4\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0018 - recall_1: 1.0000 - precision_1: 1.0000 - val_loss: 1.1758e-04 - val_recall_1: 1.0000 - val_precision_1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_ds, epochs=4, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90116a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: F:\\trigger-word-detection\\trigger_word_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: F:\\trigger-word-detection\\trigger_word_0\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(os.getcwd() , 'trigger_word_0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
